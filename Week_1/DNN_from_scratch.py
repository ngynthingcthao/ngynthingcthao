# -*- coding: utf-8 -*-
"""Week_01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OjdMzFjf3-CFj7kWosbm_muJR5YXuU7p

#Chuẩn bị data
"""

import numpy as np
import struct

import gdown

# Danh sách các ID tệp và tên tệp đầu ra tương ứng
file_ids = [
    ('1_b4PBobYqmVGnNS9ims2avqj_DfL4hsz', 'train-images'),
    ('1XcLaHEZ-6L-kxkbfnpA6FOqvBJxbkEfk', 'train-labels'),
    ('1OJRE4y46VSrKQefYh4h2qRU2QbeEhux7', 'test-images'),
    ('1t_ck3UJZdhdyZbIPZeDLn9tm9pMmlTba', 'test-labels')
]

# Tải tất cả các tệp trong danh sách
for file_id, output in file_ids:
    url = f'https://drive.google.com/uc?id={file_id}'
    gdown.download(url, output=output, quiet=False, fuzzy=False)

def load_mnist_images(filename):
  with open(filename, 'rb') as f:
    magic, num, rows, cols = struct.unpack(">IIII", f.read(16))
    images = np.fromfile(f, dtype=np.uint8).reshape(num, rows*cols)
    return images / 255.0


def load_mnist_labels(filename):
  with open(filename, 'rb') as f:
    magic, num = struct.unpack('>II', f.read(8))
    labels = np.fromfile(f, dtype=np.uint8)
    return labels

X_train = load_mnist_images('train-images')
y_train = load_mnist_labels('train-labels')
X_test = load_mnist_images('test-images')
y_test = load_mnist_labels('test-labels')

def one_hot_encode(labels, num_classes=10):
  return np.eye(num_classes)[labels]

y_train = one_hot_encode(y_train)
y_test = one_hot_encode(y_test)

"""#Xây dựng mô hình"""

#Khởi tạo tham số
def initialize_parameters(input_size, hidden_size, output_size):
  W1 = np.random.randn(input_size, hidden_size) * 0.01
  b1 = np.zeros((1, hidden_size))
  W2 = np.random.randn(hidden_size, output_size) * 0.01
  b2 = np.zeros((1, output_size))
  return W1, b1, W2, b2

#Hàm kích hoạt

def relu(Z):
  return np.maximum(0, Z)

def sigmoid(Z):
  return 1 / (1 + np.exp(-Z))

def relu_deriv(Z):
    return (Z > 0).astype(float)

def sigmoid_deriv(Z):
    sig = sigmoid(Z)
    return sig * (1 - sig)

def softmax(Z):
  expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))
  return expZ / np.sum(expZ, axis=1, keepdims=True)

#Forward Propagation
def forward_propagation(X, W1, b1, W2, b2, activation_func):
  Z1 = X.dot(W1) + b1
  A1 = activation_func(Z1)
  Z2 = A1.dot(W2) + b2
  A2 = softmax(Z2)
  return Z1, A1, Z2, A2

#Tính loss
def compute_loss(A2, Y):
  m = Y.shape[0]
  log_probs = -np.log(A2[range(m), Y.argmax(axis=1)])
  loss = np.sum(log_probs) / m
  return loss

#Backward Propagation
def backward_propagation(X, Y, Z1, A1, Z2, A2, W1, W2, activation_deriv):
    m = X.shape[0]
    dZ2 = A2 - Y
    dW2 = A1.T.dot(dZ2) / m
    db2 = np.sum(dZ2, axis=0, keepdims=True) / m
    dA1 = dZ2.dot(W2.T)
    dZ1 = dA1 * activation_deriv(Z1)
    dW1 = X.T.dot(dZ1) / m
    db1 = np.sum(dZ1, axis=0, keepdims=True) / m
    return dW1, db1, dW2, db2

#Update parameters
def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):
    W1 -= learning_rate * dW1
    b1 -= learning_rate * db1
    W2 -= learning_rate * dW2
    b2 -= learning_rate * db2
    return W1, b1, W2, b2

"""#Training

"""

def train(X, Y, W1, b1, W2, b2, batch_size, learning_rate, epochs, activation_func, activation_deriv):
    m = X.shape[0]
    for epoch in range(epochs):
        for i in range(0, m, batch_size):
            X_batch = X[i:i+batch_size]
            Y_batch = Y[i:i+batch_size]
            Z1, A1, Z2, A2 = forward_propagation(X_batch, W1, b1, W2, b2, activation_func)
            dW1, db1, dW2, db2 = backward_propagation(X_batch, Y_batch, Z1, A1, Z2, A2, W1, W2, activation_deriv)
            W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)
    return W1, b1, W2, b2

def predict(X, W1, b1, W2, b2, activation_func):
    _, _, _, A2 = forward_propagation(X, W1, b1, W2, b2, activation_func)
    return np.argmax(A2, axis=1)

from statistics import mean, stdev

# Danh sách siêu tham số
hyperparams = [
    (32, 0.1, 16, relu, relu_deriv),
    (16, 0.01, 64, sigmoid, sigmoid_deriv),
    (64, 0.05, 32, relu, relu_deriv),
    (32, 0.001, 128, sigmoid, sigmoid_deriv),
    (16, 0.1, 32, relu, relu_deriv),
]

results = []

for batch_size, lr, hidden_size, act_func, act_deriv in hyperparams:
    accuracies = []
    for _ in range(5):
        W1, b1, W2, b2 = initialize_parameters(784, hidden_size, 10)
        W1, b1, W2, b2 = train(X_train, y_train, W1, b1, W2, b2, batch_size, lr, 10, act_func, act_deriv)
        y_pred = predict(X_test, W1, b1, W2, b2, act_func)
        accuracy = np.mean(y_pred == y_test.argmax(axis=1))
        accuracies.append(accuracy)
    mean_acc = mean(accuracies)
    std_acc = stdev(accuracies)
    results.append((batch_size, lr, hidden_size, act_func.__name__, mean_acc, std_acc))

print(results)

