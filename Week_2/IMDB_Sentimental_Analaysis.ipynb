{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ad6098",
   "metadata": {},
   "source": [
    "# Cài đặt thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27e85f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b3902",
   "metadata": {},
   "source": [
    "# Data Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f21a0502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1FyX7UavGoqU28I_2owXy8KM4HCTXOql2\n",
      "To: c:\\Users\\Hello!!!\\Documents\\thuc-hanh-deep-learning\\Week_2\\IMDB_Dataset\n",
      "100%|██████████| 66.2M/66.2M [00:01<00:00, 37.2MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'IMDB_Dataset'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "gdown.download(f'https://drive.google.com/uc?id=1FyX7UavGoqU28I_2owXy8KM4HCTXOql2', output = 'IMDB_Dataset', quiet= False, fuzzy= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c6b0f",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4fc6c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB_Dataset')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a04eebd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "566d0af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hello!!!\\AppData\\Local\\Temp\\ipykernel_18536\\3298220320.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data.replace({'sentiment': {'positive': 1, 'negative': 0}}, inplace= True)\n"
     ]
    }
   ],
   "source": [
    "data.replace({'sentiment': {'positive': 1, 'negative': 0}}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "859b059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples = data[:10000]\n",
    "train_data, test_data = train_test_split(data_samples, test_size= 0.5, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70530baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "1    2557\n",
      "0    2443\n",
      "Name: count, dtype: int64\n",
      "sentiment\n",
      "0    2529\n",
      "1    2471\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra dữ liệu có cân bằng chưa => Ta thấy sự chênh lệch của nhãn 0 và 1 không nhiều nên không cần áp dụng các kỹ thuật cân bằng dữ liệu\n",
    "print(train_data['sentiment'].value_counts())\n",
    "print(test_data['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9edb4737",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 5000)\n",
    "tokenizer.fit_on_texts(train_data['review'])\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(train_data['review']), maxlen= 500)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(test_data['review']), maxlen= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3e3866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_data['sentiment']\n",
    "Y_test = test_data['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dcefd9",
   "metadata": {},
   "source": [
    "# Building to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92110e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hidden_layers, neurons_per_layer, activation, dropout_rate,\n",
    "                optimizer, learning_rate, embedding_dim=100):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Embedding layer\n",
    "    model.add(Embedding(input_dim= 5000, output_dim= 128, input_length=500))\n",
    "\n",
    "    # Hidden layers\n",
    "    for i in range(hidden_layers):\n",
    "        if i == 0:\n",
    "            model.add(Bidirectional(LSTM(neurons_per_layer, return_sequences=(hidden_layers > 1))))\n",
    "        elif i == hidden_layers - 1:\n",
    "            model.add(Bidirectional(LSTM(neurons_per_layer)))\n",
    "        else:\n",
    "            model.add(Bidirectional(LSTM(neurons_per_layer, return_sequences=True)))\n",
    "\n",
    "        # Add dropout after each LSTM layer\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    if optimizer.lower() == 'adam':\n",
    "        opt = tensorflow.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer.lower() == 'rmsprop':\n",
    "        opt = tensorflow.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer.lower() == 'sgd':\n",
    "        opt = tensorflow.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f2e8c",
   "metadata": {},
   "source": [
    "# Setting Hypermeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d3c1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    # Config 1:\n",
    "      {\n",
    "        'name': 'No.1',\n",
    "        'batch_size': 64,\n",
    "        'learning_rate': 0.001,\n",
    "        'hidden_layers': 1,\n",
    "        'neurons_per_layer': 64,\n",
    "        'activation': 'relu',\n",
    "        'dropout_rate': 0.1,\n",
    "        'optimizer': 'rmsprop',\n",
    "        'epochs': 5\n",
    "    },\n",
    "    \n",
    "    # Config 2:\n",
    "    {\n",
    "        'name': 'No.2',\n",
    "        'batch_size': 128,\n",
    "        'learning_rate': 0.01,\n",
    "        'hidden_layers': 2,\n",
    "        'neurons_per_layer': 64,\n",
    "        'activation': 'relu',\n",
    "        'dropout_rate': 0.2,\n",
    "        'optimizer': 'adam',\n",
    "        'epochs': 5\n",
    "    },\n",
    "    # Config 3:\n",
    "    {\n",
    "        'name': 'No.3',\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 0.001,\n",
    "        'hidden_layers': 1,\n",
    "        'neurons_per_layer': 128,\n",
    "        'activation': 'tanh',\n",
    "        'dropout_rate': 0.2,\n",
    "        'optimizer': 'adam',\n",
    "        'epochs': 5\n",
    "    },\n",
    "    # Config 4:\n",
    "        {\n",
    "        'name': 'No.4',\n",
    "        'batch_size': 128,\n",
    "        'learning_rate': 0.001,\n",
    "        'hidden_layers': 3,\n",
    "        'neurons_per_layer': 128,\n",
    "        'activation': 'relu',\n",
    "        'dropout_rate': 0.2,\n",
    "        'optimizer': 'adam',\n",
    "        'epochs': 5\n",
    "    },\n",
    "    # Config 5:\n",
    "    {\n",
    "        'name': 'No.5',\n",
    "        'batch_size': 64,\n",
    "        'learning_rate': 0.001,\n",
    "        'hidden_layers': 2,\n",
    "        'neurons_per_layer': 64,\n",
    "        'activation': 'relu',\n",
    "        'dropout_rate': 0.3,\n",
    "        'optimizer': 'rmsprop',\n",
    "        'epochs': 5\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe3deb",
   "metadata": {},
   "source": [
    "# Training and Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734bc548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with configuration: No.1\n",
      "Parameters: {'batch_size': 64, 'learning_rate': 0.001, 'hidden_layers': 1, 'neurons_per_layer': 64, 'activation': 'relu', 'dropout_rate': 0.1, 'optimizer': 'rmsprop', 'epochs': 5}\n",
      "  Run 1/3\n",
      "Epoch 1/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 412ms/step - accuracy: 0.5075 - loss: 0.6925 - val_accuracy: 0.4980 - val_loss: 0.7490\n",
      "Epoch 2/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 418ms/step - accuracy: 0.6750 - loss: 0.6270 - val_accuracy: 0.7700 - val_loss: 0.5020\n",
      "Epoch 3/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 407ms/step - accuracy: 0.7996 - loss: 0.4643 - val_accuracy: 0.8070 - val_loss: 0.4388\n",
      "Epoch 4/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 408ms/step - accuracy: 0.8591 - loss: 0.3458 - val_accuracy: 0.8040 - val_loss: 0.4438\n",
      "Epoch 5/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 414ms/step - accuracy: 0.8740 - loss: 0.3163 - val_accuracy: 0.8050 - val_loss: 0.4420\n",
      "    Test accuracy: 0.8084\n",
      "  Run 2/3\n",
      "Epoch 1/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 423ms/step - accuracy: 0.4959 - loss: 0.6937 - val_accuracy: 0.5210 - val_loss: 0.6874\n",
      "Epoch 2/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 434ms/step - accuracy: 0.6124 - loss: 0.6630 - val_accuracy: 0.7480 - val_loss: 0.5194\n",
      "Epoch 3/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 412ms/step - accuracy: 0.7692 - loss: 0.4978 - val_accuracy: 0.8130 - val_loss: 0.4221\n",
      "Epoch 4/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 409ms/step - accuracy: 0.8564 - loss: 0.3648 - val_accuracy: 0.8030 - val_loss: 0.4412\n",
      "Epoch 5/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 746ms/step - accuracy: 0.8723 - loss: 0.3188 - val_accuracy: 0.8260 - val_loss: 0.4119\n",
      "    Test accuracy: 0.8182\n",
      "  Run 3/3\n",
      "Epoch 1/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 952ms/step - accuracy: 0.5117 - loss: 0.6926 - val_accuracy: 0.5770 - val_loss: 0.6678\n",
      "Epoch 2/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 948ms/step - accuracy: 0.6835 - loss: 0.6205 - val_accuracy: 0.7390 - val_loss: 0.5267\n",
      "Epoch 3/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 619ms/step - accuracy: 0.7986 - loss: 0.4534 - val_accuracy: 0.7900 - val_loss: 0.4640\n",
      "Epoch 4/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 404ms/step - accuracy: 0.8354 - loss: 0.3842 - val_accuracy: 0.8070 - val_loss: 0.4381\n",
      "Epoch 5/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 411ms/step - accuracy: 0.8745 - loss: 0.3167 - val_accuracy: 0.7470 - val_loss: 0.5893\n",
      "    Test accuracy: 0.8122\n",
      "  Mean accuracy: 0.8129\n",
      "  Standard deviation: 0.0040\n",
      "\n",
      "Training with configuration: No.2\n",
      "Parameters: {'batch_size': 128, 'learning_rate': 0.01, 'hidden_layers': 2, 'neurons_per_layer': 64, 'activation': 'relu', 'dropout_rate': 0.2, 'optimizer': 'adam', 'epochs': 5}\n",
      "  Run 1/3\n",
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 9s/step - accuracy: 0.5699 - loss: 0.6795 - val_accuracy: 0.7370 - val_loss: 0.5578\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 10s/step - accuracy: 0.8461 - loss: 0.3895 - val_accuracy: 0.7670 - val_loss: 0.6154\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 7s/step - accuracy: 0.9082 - loss: 0.2415 - val_accuracy: 0.7390 - val_loss: 0.6421\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 12s/step - accuracy: 0.9451 - loss: 0.1557 - val_accuracy: 0.7800 - val_loss: 0.6118\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 13s/step - accuracy: 0.9728 - loss: 0.0907 - val_accuracy: 0.7750 - val_loss: 0.7818\n",
      "    Test accuracy: 0.7994\n",
      "  Run 2/3\n",
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 12s/step - accuracy: 0.5562 - loss: 0.6952 - val_accuracy: 0.7260 - val_loss: 0.5558\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 10s/step - accuracy: 0.8225 - loss: 0.4363 - val_accuracy: 0.7180 - val_loss: 0.5508\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 10s/step - accuracy: 0.8902 - loss: 0.2937 - val_accuracy: 0.7030 - val_loss: 0.5991\n",
      "    Test accuracy: 0.7216\n",
      "  Run 3/3\n",
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 11s/step - accuracy: 0.5715 - loss: 0.6822 - val_accuracy: 0.6740 - val_loss: 0.5986\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 14s/step - accuracy: 0.7976 - loss: 0.4467 - val_accuracy: 0.7740 - val_loss: 0.5577\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 13s/step - accuracy: 0.8749 - loss: 0.3115 - val_accuracy: 0.6610 - val_loss: 0.6889\n",
      "Epoch 4/5\n",
      "\u001b[1m 9/32\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:15\u001b[0m 14s/step - accuracy: 0.8314 - loss: 0.4206"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "best_accuracy = 0.0\n",
    "best_model = None\n",
    "best_config = None\n",
    "best_run = None\n",
    "\n",
    "for config in configs:\n",
    "    config_results = []\n",
    "\n",
    "    print(f\"\\nTraining with configuration: {config['name']}\")\n",
    "    print(\"Parameters:\", {k: v for k, v in config.items() if k != 'name'})\n",
    "\n",
    "    # Run 3 times for each configuration\n",
    "    for run in range(3):\n",
    "        print(f\"  Run {run+1}/3\")\n",
    "\n",
    "        # Build model\n",
    "        model = build_model(\n",
    "            hidden_layers=config['hidden_layers'],\n",
    "            neurons_per_layer=config['neurons_per_layer'],\n",
    "            activation=config['activation'],\n",
    "            dropout_rate=config['dropout_rate'],\n",
    "            optimizer=config['optimizer'],\n",
    "            learning_rate=config['learning_rate']\n",
    "        )\n",
    "\n",
    "        # Define early stopping\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=2,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            X_train, Y_train,\n",
    "            batch_size=config['batch_size'],\n",
    "            epochs=config['epochs'],\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Evaluate model\n",
    "        _, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        config_results.append(accuracy)\n",
    "\n",
    "        print(f\"    Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Check if this model has the best accuracy\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "            best_config = config['name']\n",
    "            best_run = run + 1\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    mean_accuracy = np.mean(config_results)\n",
    "    std_accuracy = np.std(config_results)\n",
    "\n",
    "    print(f\"  Mean accuracy: {mean_accuracy:.4f}\")\n",
    "    print(f\"  Standard deviation: {std_accuracy:.4f}\")\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'config': config['name'],\n",
    "        'accuracies': config_results,\n",
    "        'mean': mean_accuracy,\n",
    "        'std': std_accuracy\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9199dc4f",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec51a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_model.save('best_model.keras')\n",
    "print(f\"\\nBest model saved with accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Configuration: {best_config}, Run: {best_run}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb9467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
